{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "85b769aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import math\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8334f40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Github\\\\Stomach-Status-Classification\\\\Experiment\\\\Approach\\\\SVM'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c40a59e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7a47c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Github\\\\Stomach-Status-Classification'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c33c199b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:\\\\Github\\\\Stomach-Status-Classification\\\\Data set\\\\kmean_dataset\\\\sift_test_0_3_0.04_10_1.6histo4.csv', 'D:\\\\Github\\\\Stomach-Status-Classification\\\\Data set\\\\kmean_dataset\\\\sift_test_0_3_0.04_10_1.6histo5.csv', 'D:\\\\Github\\\\Stomach-Status-Classification\\\\Data set\\\\kmean_dataset\\\\sift_test_0_3_0.04_10_1.6histo6.csv', 'D:\\\\Github\\\\Stomach-Status-Classification\\\\Data set\\\\kmean_dataset\\\\sift_train_0_3_0.04_10_1.6histo4.csv', 'D:\\\\Github\\\\Stomach-Status-Classification\\\\Data set\\\\kmean_dataset\\\\sift_train_0_3_0.04_10_1.6histo5.csv', 'D:\\\\Github\\\\Stomach-Status-Classification\\\\Data set\\\\kmean_dataset\\\\sift_train_0_3_0.04_10_1.6histo6.csv']\n"
     ]
    }
   ],
   "source": [
    "main_data_dir = os.getcwd() + \"\\\\Data set\"\n",
    "kmean_data_dir = main_data_dir + \"\\\\kmean_dataset\"\n",
    "import glob\n",
    "\n",
    "sift_kmean_data = [x for x in glob.glob(kmean_data_dir + '\\\\*') if 'sift' and 'histo' in x]\n",
    "print(sift_kmean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "580af549",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:\\\\Github\\\\Stomach-Status-Classification\\\\Data set\\\\kmean_dataset\\\\sift_train_0_3_0.04_10_1.6histo4.csv', 'D:\\\\Github\\\\Stomach-Status-Classification\\\\Data set\\\\kmean_dataset\\\\sift_train_0_3_0.04_10_1.6histo5.csv', 'D:\\\\Github\\\\Stomach-Status-Classification\\\\Data set\\\\kmean_dataset\\\\sift_train_0_3_0.04_10_1.6histo6.csv']\n",
      "\n",
      "['D:\\\\Github\\\\Stomach-Status-Classification\\\\Data set\\\\kmean_dataset\\\\sift_test_0_3_0.04_10_1.6histo4.csv', 'D:\\\\Github\\\\Stomach-Status-Classification\\\\Data set\\\\kmean_dataset\\\\sift_test_0_3_0.04_10_1.6histo5.csv', 'D:\\\\Github\\\\Stomach-Status-Classification\\\\Data set\\\\kmean_dataset\\\\sift_test_0_3_0.04_10_1.6histo6.csv']\n"
     ]
    }
   ],
   "source": [
    "sift_kmean_train_paths = [x for x in sift_kmean_data if 'train' in x]\n",
    "sift_kmean_test_paths = [x for x in sift_kmean_data if 'test' in x]\n",
    "print(sift_kmean_train_paths)\n",
    "print()\n",
    "print(sift_kmean_test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "417488f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Github\\Stomach-Status-Classification\\Data set\\kmean_dataset\\sift_train_0_3_0.04_10_1.6histo4.csv\n",
      "D:\\Github\\Stomach-Status-Classification\\Data set\\kmean_dataset\\sift_train_0_3_0.04_10_1.6histo5.csv\n",
      "D:\\Github\\Stomach-Status-Classification\\Data set\\kmean_dataset\\sift_train_0_3_0.04_10_1.6histo6.csv\n"
     ]
    }
   ],
   "source": [
    "sift_kmean_train4_paths = [x for x in sift_kmean_train_paths if 'histo4' in x][0]\n",
    "sift_kmean_train5_paths = [x for x in sift_kmean_train_paths if 'histo5' in x][0]\n",
    "sift_kmean_train6_paths = [x for x in sift_kmean_train_paths if 'histo6' in x][0]\n",
    "\n",
    "print(sift_kmean_train4_paths)\n",
    "print(sift_kmean_train5_paths)\n",
    "print(sift_kmean_train6_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdd5c196",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Github\\Stomach-Status-Classification\\Data set\\kmean_dataset\\sift_test_0_3_0.04_10_1.6histo4.csv\n",
      "D:\\Github\\Stomach-Status-Classification\\Data set\\kmean_dataset\\sift_test_0_3_0.04_10_1.6histo5.csv\n",
      "D:\\Github\\Stomach-Status-Classification\\Data set\\kmean_dataset\\sift_test_0_3_0.04_10_1.6histo6.csv\n"
     ]
    }
   ],
   "source": [
    "sift_kmean_test4_paths = [x for x in sift_kmean_test_paths if 'histo4' in x][0]\n",
    "sift_kmean_test5_paths = [x for x in sift_kmean_test_paths if 'histo5' in x][0]\n",
    "sift_kmean_test6_paths = [x for x in sift_kmean_test_paths if 'histo6' in x][0]\n",
    "\n",
    "print(sift_kmean_test4_paths)\n",
    "print(sift_kmean_test5_paths)\n",
    "print(sift_kmean_test6_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fcda562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88, 7) (88, 8) (88, 9) (88, 7) (88, 8) (88, 9)\n"
     ]
    }
   ],
   "source": [
    "df_train_4 = pd.read_csv(sift_kmean_train4_paths)\n",
    "df_train_5 = pd.read_csv(sift_kmean_train5_paths)\n",
    "df_train_6 = pd.read_csv(sift_kmean_train6_paths)\n",
    "\n",
    "df_test_4 = pd.read_csv(sift_kmean_test4_paths)\n",
    "df_test_5 = pd.read_csv(sift_kmean_test5_paths)\n",
    "df_test_6 = pd.read_csv(sift_kmean_test6_paths)\n",
    "\n",
    "print(df_train_4.shape, df_train_5.shape, df_train_6.shape, df_test_4.shape, df_test_5.shape, df_test_6.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0d6ffe7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>CHGastro_Normal_001.png</td>\n",
       "      <td>15</td>\n",
       "      <td>42</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CHGastro_Normal_003.png</td>\n",
       "      <td>10</td>\n",
       "      <td>46</td>\n",
       "      <td>53</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CHGastro_Normal_006.png</td>\n",
       "      <td>31</td>\n",
       "      <td>54</td>\n",
       "      <td>26</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CHGastro_Normal_007.png</td>\n",
       "      <td>29</td>\n",
       "      <td>104</td>\n",
       "      <td>46</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CHGastro_Normal_009.png</td>\n",
       "      <td>11</td>\n",
       "      <td>75</td>\n",
       "      <td>56</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                        0   1    2   3   4  5\n",
       "0           0  CHGastro_Normal_001.png  15   42  25   7  0\n",
       "1           1  CHGastro_Normal_003.png  10   46  53   8  0\n",
       "2           2  CHGastro_Normal_006.png  31   54  26  18  0\n",
       "3           3  CHGastro_Normal_007.png  29  104  46  25  0\n",
       "4           4  CHGastro_Normal_009.png  11   75  56   6  0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4940376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>CHGastro_Normal_002.png</td>\n",
       "      <td>32</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>37</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CHGastro_Normal_004.png</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CHGastro_Normal_005.png</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CHGastro_Normal_008.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CHGastro_Normal_011.png</td>\n",
       "      <td>9</td>\n",
       "      <td>43</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                        0   1   2   3   4   5   6  7\n",
       "0           0  CHGastro_Normal_002.png  32  12  15  37  21  14  0\n",
       "1           1  CHGastro_Normal_004.png  18   8  10  30  16   9  0\n",
       "2           2  CHGastro_Normal_005.png   2   2   0  19   4   1  0\n",
       "3           3  CHGastro_Normal_008.png   1   1   8  19   4   6  0\n",
       "4           4  CHGastro_Normal_011.png   9  43   5  24   1  33  0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2089c5bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Confusion Matrix': {'TP': 50,\n",
       "  'TN': 56,\n",
       "  'FN': 53,\n",
       "  'FP': 53,\n",
       "  'precision': 0.4854368932038835,\n",
       "  'recall': 0.4854368932038835,\n",
       "  'f1_score': 0.4854368932038835,\n",
       "  'sensitivity': 0.4854368932038835,\n",
       "  'specificity': 0.5137614678899083,\n",
       "  'negative_predictive_value': 0.5137614678899083,\n",
       "  'false_negative_rate': 0.5145631067961165,\n",
       "  'false_positive_rate': 0.48623853211009177,\n",
       "  'false_discovery_rate': 0.5145631067961165,\n",
       "  'false_omission_rate': 0.48623853211009177,\n",
       "  'Positive_likelihood_ratio': 0.9983513464004397,\n",
       "  'Negative_likelihood_ratio': 1.0015603328710123,\n",
       "  'prevalence_threshold': 0.5002062517538599,\n",
       "  'threat_score': 0.30864197530864196,\n",
       "  'Prevalence': 0.4858490566037736,\n",
       "  'Matthews_correlation_coefficient': -7.140277066075069e-08,\n",
       "  'Fowlkes_Mallows_index': 0.9853292781642932,\n",
       "  'informedness': -0.000801638906208213,\n",
       "  'markedness': -0.000801638906208213,\n",
       "  'Diagnostic_odds_ratio': 0.9967960128159489,\n",
       "  'accuracy': 0.5,\n",
       "  'balanced_accuracy': 0.4995991805468959},\n",
       " 'ROC_AUC_SCORE': {'Macro': 0.5316060086702289,\n",
       "  'Micro': 0.5316060086702289,\n",
       "  'Weight': 0.5316060086702289},\n",
       " 'Classification Report': {'0': {'precision': 0.4854368932038835,\n",
       "   'recall': 0.5494505494505495,\n",
       "   'f1-score': 0.5154639175257733,\n",
       "   'support': 91},\n",
       "  '1': {'precision': 0.5773195876288659,\n",
       "   'recall': 0.5137614678899083,\n",
       "   'f1-score': 0.5436893203883495,\n",
       "   'support': 109},\n",
       "  'accuracy': 0.53,\n",
       "  'macro avg': {'precision': 0.5313782404163747,\n",
       "   'recall': 0.5316060086702289,\n",
       "   'f1-score': 0.5295766189570614,\n",
       "   'support': 200},\n",
       "  'weighted avg': {'precision': 0.5355129616654989,\n",
       "   'recall': 0.53,\n",
       "   'f1-score': 0.5308467620858773,\n",
       "   'support': 200}}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class utils:\n",
    "    def __init__(self, confusion_matrix, y_true, y_pred):\n",
    "        \"\"\"\n",
    "            - confusion_matrix: 2x2 numpy array\n",
    "            - y_true: array of label\n",
    "            - y_pred: array of output value calculated by model\n",
    "            - fold_count: number of folds\n",
    "        \"\"\"\n",
    "        \n",
    "        # Initilize all indicator\n",
    "        self.TP = confusion_matrix[0][0] # true positive\n",
    "        self.FN = confusion_matrix[1][0] # false negative\n",
    "        self.FP = confusion_matrix[1][0] # false positive\n",
    "        self.TN = confusion_matrix[1][1] # true negative\n",
    "        self.precision = self.TP/(self.FN +  self.TP) # Precision Score - Positive Predictive Value\n",
    "        self.recall = self.TP / (self.TP + self.FN)\n",
    "        self.f1_score =  (2 * self.TP) / (2 * self.TP + self.FP + self.FN)\n",
    "        self.sensitivity = self.TP / (self.TP + self.FN) # True Positive Rate\n",
    "        self.specificity = self.TN / (self.TN + self.FP) # False Positive Rate\n",
    "        self.negative_predictive_value = self.TN / (self.TN + self.FN) # Negative Predictive Value\n",
    "        self.false_negative_rate = self.FN / (self.FN + self.TP) # False Negative Rate\n",
    "        self.false_positive_rate = self.FP / (self.FP + self.TN) # False Positive Rate\n",
    "        self.false_discovery_rate = self.FP / (self.FP + self.TP) # False Discovery Rate\n",
    "        self.false_omission_rate = self.FN / (self.FN + self.TN) # False Ommision Rate\n",
    "        self.positive_likelihood_ratio = self.sensitivity / self.false_positive_rate # Positive Likelihood Ratio\n",
    "        self.negative_likelihood_ratio = self.false_negative_rate / self.specificity # Negative Likelihood Ratio\n",
    "        self.prevalence_threshold = math.sqrt(self.false_positive_rate) / (math.sqrt(self.sensitivity) + \n",
    "                                                                      math.sqrt(self.false_positive_rate)) # Prevalance Threshold\n",
    "        self.threat_score = self.TP / (self.TN + self.FN + self.FP) # Threat Score\n",
    "        self.prevalence = (self.TP + self.FN)/(self.TP + self.FN + self.TN + self.FP) # Prevalance \n",
    "        #  Matthews correlation coefficient\n",
    "        self.matthews_correlation_coefficient = (self.TP*self.TN - self.FN*self.FP) / ((self.TP + self.FP)\n",
    "                                                                                       *(self.TP + self.FN)\n",
    "                                                                                       *(self.TN + self.FP)\n",
    "                                                                                       *(self.TN + self.FN))\n",
    "        self.fowlkes_mallows_index = math.sqrt(self.sensitivity + self.precision) # Fowlkesâ€“Mallows index\n",
    "        self.informedness = self.sensitivity + self.specificity - 1 # informedness\n",
    "        self.markedness = self.precision + self.negative_predictive_value - 1 # markedness\n",
    "        self.diagnostic_odds_ratio = self.positive_likelihood_ratio / self.negative_likelihood_ratio # Diagnostic odds ratio\n",
    "        self.accuracy = (self.TP + self.TN) / (self.TP + self.TN + self.FP + self.FN)\n",
    "        self.balanced_accuracy = (self.sensitivity + self.specificity) / 2\n",
    "        self.roc_auc_macro = roc_auc_score(y_true, y_pred)\n",
    "        self.roc_auc_micro = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "        self.roc_auc_weighted = roc_auc_score(y_true, y_pred, average = 'weighted')\n",
    "        self.cls_report = classification_report(y_true, y_pred)\n",
    "        \n",
    "        # Initilize the structure of output_dicts\n",
    "        self.confusion_matrix = {\n",
    "            \"TP\" : self.TP,\n",
    "            \"TN\" : self.TN,\n",
    "            \"FN\" : self.FN,\n",
    "            \"FP\" : self.FP,\n",
    "            \"precision\" : self.precision,\n",
    "            \"recall\" : self.recall,\n",
    "            \"f1_score\" : self.f1_score,\n",
    "            \"sensitivity\" : self.sensitivity,\n",
    "            \"specificity\" : self.specificity,\n",
    "            \"negative_predictive_value\" : self.negative_predictive_value,\n",
    "            \"false_negative_rate\" : self.false_negative_rate,\n",
    "            \"false_positive_rate\" : self.false_positive_rate,\n",
    "            \"false_discovery_rate\" : self.false_discovery_rate,\n",
    "            \"false_omission_rate\" : self.false_omission_rate,\n",
    "            \"Positive_likelihood_ratio\" : self.positive_likelihood_ratio,\n",
    "            \"Negative_likelihood_ratio\" : self.negative_likelihood_ratio,\n",
    "            \"prevalence_threshold\" : self.prevalence_threshold,\n",
    "            \"threat_score\" : self.threat_score,\n",
    "            \"Prevalence\" : self.prevalence,\n",
    "            \"Matthews_correlation_coefficient\" : self.matthews_correlation_coefficient,\n",
    "            \"Fowlkes_Mallows_index\" : self.fowlkes_mallows_index,\n",
    "            \"informedness\" : self.informedness,\n",
    "            \"markedness\" : self.markedness,\n",
    "            \"Diagnostic_odds_ratio\" : self.diagnostic_odds_ratio,\n",
    "            \"accuracy\" : self.accuracy,\n",
    "            \"balanced_accuracy\" : self.balanced_accuracy\n",
    "        }\n",
    "        \n",
    "        self.roc_auc_score = {\n",
    "            \"Macro\": self.roc_auc_macro, \n",
    "            \"Micro\": self.roc_auc_micro,\n",
    "            \"Weight\": self.roc_auc_weighted\n",
    "        }\n",
    "        \n",
    "        self.sub_dict = {\n",
    "            \"Confusion Matrix\" : self.confusion_matrix,\n",
    "            \"ROC_AUC_SCORE\" : self.roc_auc_score,\n",
    "            \"Classification Report\" : classification_report(y_true.tolist(), y_pred.tolist(), \n",
    "                                                            labels = [0, 1], # 0 : Licit, 1 : Illicit\n",
    "                                                            output_dict = True)\n",
    "        }\n",
    "    def get_value(self):\n",
    "        return self.sub_dict\n",
    "        \n",
    "# Test \n",
    "y_true = np.array([randint(0,1) for x in range(200)])\n",
    "y_pred = np.array([randint(0,1) for x in range(200)])\n",
    "confusion_matrix_test = confusion_matrix(y_true, y_pred)\n",
    "base_utils = utils(confusion_matrix_test, y_true, y_pred)\n",
    "base_utils.get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "98239c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "    def __init__(self, fold_count, X, y):\n",
    "        self.fold_count = fold_count\n",
    "        self.param_grid = {\n",
    "            \"kernel\" : [\"linear\", \"rbf\", \"sigmoid\"],\n",
    "            \"degree\" : [1, 2, 3, 5, 7, 9],\n",
    "            \"gamma\" : [\"scale\", \"auto\"],\n",
    "            \"class_weight\" : [\"balanced\", None]\n",
    "        }\n",
    "        self.kf = KFold(n_splits=fold_count)\n",
    "        self.history = {}\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def get_fold_value(self):\n",
    "        return self.kf        \n",
    "        \n",
    "    def training(self, kernel, degree, gamma, class_weight, train_case):\n",
    "    \n",
    "        # output_dict initilize\n",
    "        output_dict = {}\n",
    "    \n",
    "        # poiter track the index of fold\n",
    "        fold_index = 0\n",
    "    \n",
    "        for train_index, test_index in self.kf.split(self.X):\n",
    "            print(\"\\tFold: {}\".format(fold_index))\n",
    "            print(\"\\tTRAIN:\", train_index, \"\\n\\tTEST:\", test_index)\n",
    "        \n",
    "            # folding data\n",
    "            X_train, X_test = self.X[train_index], self.X[test_index]\n",
    "            y_train, y_test = self.y[train_index], self.y[test_index]\n",
    "    \n",
    "            # Training\n",
    "            print(\"\\t\\tTraining : {}\".format(fold_index), end = \" -- \")\n",
    "            print(\"Start: {}\".format(datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")), end=\" --- \")\n",
    "            model_svc = SVC(kernel = kernel, \n",
    "                            degree = degree, \n",
    "                            gamma = gamma, \n",
    "                            class_weight = class_weight\n",
    "                           )\n",
    "            model_svc.fit(X_train,y_train)\n",
    "            print(\"End: {}\".format(datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")))\n",
    "        \n",
    "            # Testing\n",
    "            print(\"\\t\\tValidation: {}\".format(fold_index), end = \" -- \")\n",
    "            print(\"Start: {}\".format(datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")), end=\"---\")\n",
    "            y_pred = model_svc.predict(X_test)\n",
    "            print(\"End: {}\".format(datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")))\n",
    "        \n",
    "            # Evaluation\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "            current_utils = utils(cm, y_test, y_pred)\n",
    "            output_dict[\"fold_{}\".format(fold_index)] = current_utils.get_value()\n",
    "            \n",
    "            fold_index += 1\n",
    "        print(\"\\n\")\n",
    "        return output_dict \n",
    "    \n",
    "    def train(self, path):\n",
    "        count = 0\n",
    "        for x in self.param_grid[\"kernel\"]:\n",
    "            for i in self.param_grid[\"degree\"]:\n",
    "                for j in self.param_grid[\"gamma\"]:\n",
    "                    for k in self.param_grid[\"class_weight\"]:\n",
    "                        print(\"Traning Case: {}\".format(count))\n",
    "                        self.history[\"train_{}\".format(count)] = {\n",
    "                            \"param\" : {\n",
    "                                \"kernel\" : x,\n",
    "                                \"degree\" : i,\n",
    "                                \"gamma\" : j,\n",
    "                                \"class_weight\" : k,\n",
    "                            },\n",
    "                            \"train_fold\" : self.training(x, i, j, k, count)\n",
    "                        }\n",
    "                        count += 1\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(train.history, f)\n",
    "        \n",
    "        return self.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "88c1ca0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(176, 4)\n",
      "(176,)\n"
     ]
    }
   ],
   "source": [
    "def make_data(train_df, test_df):\n",
    "    train = train_df.to_numpy()[:, 2:]\n",
    "    test = test_df.to_numpy()[:, 2:]\n",
    "    \n",
    "    x_train, y_train = train[:, :-1], train[:, -1]\n",
    "    x_test, y_test = test[:, :-1], test[:, -1]\n",
    "    \n",
    "    x = np.concatenate((x_train, x_test), axis = 0)\n",
    "    y = np.concatenate((y_train, y_test), axis = 0)\n",
    "    \n",
    "    return x,y\n",
    "\n",
    "x, y = make_data(df_train_4, df_test_4)\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "caf05aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning Case: 0\n",
      "\tFold: 0\n",
      "\tTRAIN: [ 36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175] \n",
      "\tTEST: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1]\n",
      "\t\tTraining : 0 -- Start: 10/29/2022, 18:41:38 --- "
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'unknown'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [46], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetcwd() \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mExperiment\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mApproach\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mSVM\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124msvm_SVC_4_result.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m train \u001b[38;5;241m=\u001b[39m Training(\u001b[38;5;241m5\u001b[39m, X, y)\n\u001b[1;32m----> 5\u001b[0m history \u001b[38;5;241m=\u001b[39m train\u001b[38;5;241m.\u001b[39mtrain(path)\n",
      "Cell \u001b[1;32mIn [45], line 76\u001b[0m, in \u001b[0;36mTraining.train\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m     68\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraning Case: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(count))\n\u001b[0;32m     69\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(count)] \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     70\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparam\u001b[39m\u001b[38;5;124m\"\u001b[39m : {\n\u001b[0;32m     71\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m\"\u001b[39m : x,\n\u001b[0;32m     72\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdegree\u001b[39m\u001b[38;5;124m\"\u001b[39m : i,\n\u001b[0;32m     73\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m\"\u001b[39m : j,\n\u001b[0;32m     74\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m : k,\n\u001b[0;32m     75\u001b[0m                     },\n\u001b[1;32m---> 76\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_fold\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m                 }\n\u001b[0;32m     78\u001b[0m                 count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "Cell \u001b[1;32mIn [45], line 44\u001b[0m, in \u001b[0;36mTraining.training\u001b[1;34m(self, kernel, degree, gamma, class_weight, train_case)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY, \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)), end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m --- \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m model_svc \u001b[38;5;241m=\u001b[39m SVC(kernel \u001b[38;5;241m=\u001b[39m kernel, \n\u001b[0;32m     40\u001b[0m                 degree \u001b[38;5;241m=\u001b[39m degree, \n\u001b[0;32m     41\u001b[0m                 gamma \u001b[38;5;241m=\u001b[39m gamma, \n\u001b[0;32m     42\u001b[0m                 class_weight \u001b[38;5;241m=\u001b[39m class_weight\n\u001b[0;32m     43\u001b[0m                )\n\u001b[1;32m---> 44\u001b[0m \u001b[43mmodel_svc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnd: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY, \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Testing\u001b[39;00m\n",
      "File \u001b[1;32md:\\github\\stomach-status-classification\\envir\\lib\\site-packages\\sklearn\\svm\\_base.py:182\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    173\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    174\u001b[0m         X,\n\u001b[0;32m    175\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    179\u001b[0m         accept_large_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    180\u001b[0m     )\n\u001b[1;32m--> 182\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\n\u001b[0;32m    185\u001b[0m     [] \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64\n\u001b[0;32m    186\u001b[0m )\n\u001b[0;32m    187\u001b[0m solver_type \u001b[38;5;241m=\u001b[39m LIBSVM_IMPL\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl)\n",
      "File \u001b[1;32md:\\github\\stomach-status-classification\\envir\\lib\\site-packages\\sklearn\\svm\\_base.py:735\u001b[0m, in \u001b[0;36mBaseSVC._validate_targets\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_targets\u001b[39m(\u001b[38;5;28mself\u001b[39m, y):\n\u001b[0;32m    734\u001b[0m     y_ \u001b[38;5;241m=\u001b[39m column_or_1d(y, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 735\u001b[0m     \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;28mcls\u001b[39m, y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_, return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight_ \u001b[38;5;241m=\u001b[39m compute_class_weight(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight, classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, y\u001b[38;5;241m=\u001b[39my_)\n",
      "File \u001b[1;32md:\\github\\stomach-status-classification\\envir\\lib\\site-packages\\sklearn\\utils\\multiclass.py:200\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    192\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    199\u001b[0m ]:\n\u001b[1;32m--> 200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'unknown'"
     ]
    }
   ],
   "source": [
    "x, y = make_data(df_train_4, df_test_4)\n",
    "\n",
    "path = os.getcwd() + \"\\\\Experiment\\\\Approach\\\\SVM\\\\svm_SVC_4_result.pkl\"\n",
    "train = Training(5, x, y)\n",
    "history = train.train(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
