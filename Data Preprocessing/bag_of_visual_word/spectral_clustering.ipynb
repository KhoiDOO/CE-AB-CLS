{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebff94ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import SpectralClustering\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5748833b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Github\\Stomach-Status-Classification\\Data Preprocessing\\bag_of_visual_word\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73460acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Github\\Stomach-Status-Classification\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"..\")\n",
    "os.chdir(\"..\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c53c15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data_dir = os.getcwd() + \"\\\\Data set\"\n",
    "kmean_data_dir = main_data_dir + \"\\\\spc_dataset\"\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ffe08d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1eee1f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Github\\Stomach-Status-Classification\\Data set\\sift\n"
     ]
    }
   ],
   "source": [
    "descriptor = 'sift'\n",
    "\n",
    "data = main_data_dir + \"\\\\{}\".format(descriptor)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b80d441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:\\\\Github\\\\Stomach-Status-Classification\\\\Data set\\\\sift\\\\sift_train_0_3_0.04_10_1.6.json']\n",
      "['D:\\\\Github\\\\Stomach-Status-Classification\\\\Data set\\\\sift\\\\sift_test_0_3_0.04_10_1.6.json']\n"
     ]
    }
   ],
   "source": [
    "data_train = [i for i in glob.glob(data + '\\\\*') if 'train' in i]\n",
    "data_test = [i for i in glob.glob(data + '\\\\*') if 'test' in i]\n",
    "\n",
    "print(data_train)\n",
    "print(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ab29878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "def load_json(path):\n",
    "    f = open(path)\n",
    "    return  json.load(f)\n",
    "\n",
    "train_json = load_json(data_train[0])\n",
    "test_json = load_json(data_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a58294b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Github\\Stomach-Status-Classification\\Data set\\spc_dataset\\10cv_128\\sift_train_0_3_0.04_10_1.6histo_128_cv_index0.csv\n"
     ]
    }
   ],
   "source": [
    "save_train_path = main_data_dir + \"\\\\spc_dataset\\\\{0}cv_{1}\\\\\" + data_train[0].split(\"\\\\\")[-1][:-5] + \"histo_{2}_cv_index{3}.csv\"\n",
    "save_test_path = main_data_dir + \"\\\\spc_dataset\\\\{0}cv_{1}\\\\\" + data_test[0].split(\"\\\\\")[-1][:-5] + \"histo_{2}_cv_index{3}.csv\"\n",
    "print(save_train_path.format(10, 128, 128, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a325603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(lst, n):\n",
    "    random.shuffle(lst) \n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "        \n",
    "def make_data(k_choosed = 128, random_state = 42, cv = 10, test_size = 2,\n",
    "              json_data = [], train_path = None, test_path = None):\n",
    "    train_json = json_data[0]\n",
    "    test_json = json_data[1]\n",
    "    \n",
    "    train_nor_js = train_json[\"Group 1 - Normal\"]\n",
    "    train_ab_js = train_json[\"Group 2 - Abnormal\"]\n",
    "    \n",
    "    test_nor_js = test_json[\"Group 1 - Normal\"]\n",
    "    test_ab_js = test_json[\"Group 2 - Abnormal\"]\n",
    "    \n",
    "    ab_vector_lst = train_ab_js + test_ab_js\n",
    "    nor_vector_lst = train_nor_js + test_nor_js\n",
    "    \n",
    "    ab_folds = list(chunks(ab_vector_lst, round(len(ab_vector_lst)/cv)))\n",
    "    nor_folds = list(chunks(nor_vector_lst, round(len(nor_vector_lst)/cv)))\n",
    "    \n",
    "    folds = [x + y for x, y in zip(ab_folds, nor_folds)]\n",
    "    \n",
    "    for x in range(len(folds)):\n",
    "        print(\"Starting Fold : {}\".format(x))\n",
    "        print(\"\\tData Extraction from Fold\")\n",
    "        test_filenames = folds[x]\n",
    "        train_start = []\n",
    "        train_end = []\n",
    "        if folds[:x]:\n",
    "            for i in folds[:x]:\n",
    "                train_start += i \n",
    "        if folds[x+1:]:\n",
    "            for i in folds[x+1:]:\n",
    "                train_end += i \n",
    "        train_filenames = train_start + train_end\n",
    "        \n",
    "        concat_lst = []\n",
    "        print(\"\\tFinish Data Extraction from Fold\")\n",
    "        print(\"\\tData Preparing for Kmean\")\n",
    "        for img_dict in train_filenames:\n",
    "            for key in img_dict:\n",
    "                img_vector_lst = img_dict[key]\n",
    "                img_vector = np.array(img_vector_lst)\n",
    "                concat_lst.append(img_vector)\n",
    "        \n",
    "        data_cluster = concat_lst[0]\n",
    "        for i in range(1, len(concat_lst)):\n",
    "            concat_data = np.concatenate((data_cluster, concat_lst[i]), axis=0)\n",
    "            data_cluster = concat_data\n",
    "        print(\"\\tFinish Data Preparing for Model\")\n",
    "        print(\"\\tModel Training Data Extraction\")\n",
    "        save_dict = {i : [] for i in range(k_choosed+2)}\n",
    "        model = SpectralClustering(n_clusters=k_choosed, random_state = random_state, assign_labels='discretize').fit(data_cluster)\n",
    "        \n",
    "        for img_dict in train_filenames:\n",
    "            for key in img_dict:\n",
    "                img_vector_lst = img_dict[key]\n",
    "                img_vector = np.array(img_vector_lst)\n",
    "                km_vector = model.predict(np.array(img_vector))\n",
    "                his_vector = np.histogram(km_vector, bins = k_choosed, density = True)[0]\n",
    "                save_dict[0].append(key)\n",
    "                for j in range(1, k_choosed+1):\n",
    "                    save_dict[j].append(his_vector[j-1])\n",
    "                if 'Normal' in key:\n",
    "                    save_dict[k_choosed+1].append(0)\n",
    "                else:\n",
    "                    save_dict[k_choosed+1].append(1)\n",
    "        \n",
    "        if train_path:\n",
    "            df = pd.DataFrame(save_dict)\n",
    "            df.to_csv(train_path.format(cv, k_choosed, k_choosed, x))\n",
    "            \n",
    "        print(\"\\tKMean Testing Data Extraction\")\n",
    "        save_dict = {i : [] for i in range(k_choosed+2)}\n",
    "        for img_dict in test_filenames:\n",
    "            for key in img_dict:\n",
    "                img_vector_lst = img_dict[key]\n",
    "                img_vector = np.array(img_vector_lst)\n",
    "                km_vector = model.predict(np.array(img_vector))\n",
    "                his_vector = np.histogram(km_vector, bins = k_choosed, density = True)[0]\n",
    "                save_dict[0].append(key)\n",
    "                for j in range(1, k_choosed+1):\n",
    "                    save_dict[j].append(his_vector[j-1])\n",
    "                if 'Normal' in key:\n",
    "                    save_dict[k_choosed+1].append(0)\n",
    "                else:\n",
    "                    save_dict[k_choosed+1].append(1)\n",
    "        \n",
    "        if test_path:\n",
    "            df = pd.DataFrame(save_dict)\n",
    "            df.to_csv(test_path.format(cv, k_choosed, k_choosed, x))\n",
    "        print(\"\\tFinish KMean Data Extraction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78e684ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Fold : 0\n",
      "\tData Extraction from Fold\n",
      "\tFinish Data Extraction from Fold\n",
      "\tData Preparing for Kmean\n",
      "\tFinish Data Preparing for Model\n",
      "\tModel Training Data Extraction\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 65.7 GiB for an array with shape (93916, 93916) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m make_data(cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, k_choosed \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m, test_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m      2\u001b[0m           json_data \u001b[38;5;241m=\u001b[39m [train_json, test_json], \n\u001b[0;32m      3\u001b[0m           train_path \u001b[38;5;241m=\u001b[39m save_train_path, \n\u001b[0;32m      4\u001b[0m           test_path \u001b[38;5;241m=\u001b[39m save_test_path)\n",
      "Cell \u001b[1;32mIn [12], line 55\u001b[0m, in \u001b[0;36mmake_data\u001b[1;34m(k_choosed, random_state, cv, test_size, json_data, train_path, test_path)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mModel Training Data Extraction\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     54\u001b[0m save_dict \u001b[38;5;241m=\u001b[39m {i : [] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(k_choosed\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m2\u001b[39m)}\n\u001b[1;32m---> 55\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSpectralClustering\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk_choosed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massign_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdiscretize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_cluster\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img_dict \u001b[38;5;129;01min\u001b[39;00m train_filenames:\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m img_dict:\n",
      "File \u001b[1;32md:\\github\\stomach-status-classification\\envir\\lib\\site-packages\\sklearn\\cluster\\_spectral.py:735\u001b[0m, in \u001b[0;36mSpectralClustering.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    733\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdegree\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdegree\n\u001b[0;32m    734\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoef0\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef0\n\u001b[1;32m--> 735\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maffinity_matrix_ \u001b[38;5;241m=\u001b[39m pairwise_kernels(\n\u001b[0;32m    736\u001b[0m         X, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maffinity, filter_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    737\u001b[0m     )\n\u001b[0;32m    739\u001b[0m random_state \u001b[38;5;241m=\u001b[39m check_random_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n\u001b[0;32m    740\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_ \u001b[38;5;241m=\u001b[39m spectral_clustering(\n\u001b[0;32m    741\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maffinity_matrix_,\n\u001b[0;32m    742\u001b[0m     n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_clusters,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    749\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    750\u001b[0m )\n",
      "File \u001b[1;32md:\\github\\stomach-status-classification\\envir\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:2188\u001b[0m, in \u001b[0;36mpairwise_kernels\u001b[1;34m(X, Y, metric, filter_params, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   2185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown kernel \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m metric)\n\u001b[1;32m-> 2188\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32md:\\github\\stomach-status-classification\\envir\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1563\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1560\u001b[0m X, Y, dtype \u001b[38;5;241m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[0;32m   1562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(X, Y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   1565\u001b[0m \u001b[38;5;66;03m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[0;32m   1566\u001b[0m fd \u001b[38;5;241m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[1;32md:\\github\\stomach-status-classification\\envir\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1298\u001b[0m, in \u001b[0;36mrbf_kernel\u001b[1;34m(X, Y, gamma)\u001b[0m\n\u001b[0;32m   1295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gamma \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1296\u001b[0m     gamma \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m-> 1298\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[43meuclidean_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1299\u001b[0m K \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mgamma\n\u001b[0;32m   1300\u001b[0m np\u001b[38;5;241m.\u001b[39mexp(K, K)  \u001b[38;5;66;03m# exponentiate K in-place\u001b[39;00m\n",
      "File \u001b[1;32md:\\github\\stomach-status-classification\\envir\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:328\u001b[0m, in \u001b[0;36meuclidean_distances\u001b[1;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m Y_norm_squared\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;241m1\u001b[39m, Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m    323\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    324\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncompatible dimensions for Y of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mY\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    325\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY_norm_squared of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moriginal_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    326\u001b[0m         )\n\u001b[1;32m--> 328\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_euclidean_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_norm_squared\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_norm_squared\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\github\\stomach-status-classification\\envir\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:369\u001b[0m, in \u001b[0;36m_euclidean_distances\u001b[1;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[0m\n\u001b[0;32m    366\u001b[0m     distances \u001b[38;5;241m=\u001b[39m _euclidean_distances_upcast(X, XX, Y, YY)\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;66;03m# if dtype is already float64, no need to chunk and upcast\u001b[39;00m\n\u001b[1;32m--> 369\u001b[0m     distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    370\u001b[0m     distances \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m XX\n\u001b[0;32m    371\u001b[0m     distances \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m YY\n",
      "File \u001b[1;32md:\\github\\stomach-status-classification\\envir\\lib\\site-packages\\sklearn\\utils\\extmath.py:152\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    150\u001b[0m         ret \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(a, b)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 152\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    155\u001b[0m     sparse\u001b[38;5;241m.\u001b[39missparse(a)\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    159\u001b[0m ):\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 65.7 GiB for an array with shape (93916, 93916) and data type float64"
     ]
    }
   ],
   "source": [
    "make_data(cv = 10, k_choosed = 64, test_size = 2,\n",
    "          json_data = [train_json, test_json], \n",
    "          train_path = save_train_path, \n",
    "          test_path = save_test_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
